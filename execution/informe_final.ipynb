{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informe de solución\n",
    "\n",
    "En este informe responde a las preguntas especificadas dando detalles especificos de la ejecución y mostrando los resultados obtenidos de cada modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Qué pasos del plan se realizaron y qué pasos se omitieron (explica por qué)?**\n",
    "\n",
    "Los pasos que se realizaron para la creación del algoritmo fueron:\n",
    "\n",
    "1. Realizar un preprocesamiento de datos para obtener un buen resultado, revisando datos nulos, duplicados, atipicos etc.\n",
    "\n",
    "2. Realizar un analisis exploratorio de datos para identificar insights y posibles causas de cancelación por contrato, costo y servicios.\n",
    "\n",
    "3. Unir los dataframes para obtener uno consolidado con la totalidad de las caracteristicas.\n",
    "\n",
    "4. Separar los datos en entrenamiento, validación y testeo.\n",
    "\n",
    "5. Imputar datos faltantes al unir los dataframes.\n",
    "\n",
    "6. Aplicar ingeniería de caracteristicas tales como balanceo de clases, escalamiento de variables numericas, codificación de variables categoricas, selección de caracteristicas y análisis de correlación.\n",
    "\n",
    "7. Entrenar los modelos y calcular su metrica AUC para definir los mejores modelos. Se utilizó: Random_Forest, Light_GBM, CatBoost, XGboost, Logistic_Regression y una Red Neuronal Multicapa.\n",
    "\n",
    "8. Se probaron los modelos con los datos de testeo y se seleccionó el mejor modelo para obtener una métrica AUC mayor a 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ¿Qué dificultades encontraste y cómo lograste resolverlas?**\n",
    "\n",
    "Difucultades encontradas:\n",
    "\n",
    "1. Durante el entrenamiento y el testeo de los modelos al inicio se imputaron los valores asumiendo que los nulos eran usuarios que no tienen los servicios adicionales, por lo cual con fue dificil llegar a 0.85 con estos datos, el máximo valor alcanzado con esto fue de 0.75, por esta razón se decidió imputar todo con la media con Simple Imputer. Lo cual mejoro drasticamente el modelo, pasando de utilizar variables vinarias con datos discretos a netamente valores continuos.\n",
    "\n",
    "2. Al principio no utilizamos la red neuronal, sino únicamente modelos de boosting, RandomForest y Logistic Regression, sin embargo, no alcanzabamos el objetivo, por lo cual primero intentamos aumentar los hiperparametros de estos modelos para alcanzar un mejor resultado, sin embargo, esto solo generó problemas computacionales, ya que estos modelos tardaban más de 1 dia en correr. Posterior a esta prueba se utilizó una red neuronal multicapa que al probar con varias capas, utilizar diferente numero de neuronas y definir la función a mejorar como la AUC, logramos obtener el resultado esperado de 0.85 de métrica AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Cuáles fueron algunos de los pasos clave para resolver la tarea?**\n",
    "\n",
    "Durante el proyecto fue muy importante definir el plan de trabajo para tener un flujo de trabajo e ir paso a paso, adicionalmente probar con distintos modelos como la red neuronal, imputar los datos con la media y hacer una selección de caracteristicas con el análisis de correlación ayudó a obtener el resultado. \n",
    "\n",
    "Al realizar el análisis de correlación seleccionamos las caracteristicas cuyo valot absoluto de la correlación fuera mayor a 17%, con esto garantizabamos que solo las caracteristicas que tuvieran más correlación fueran seleccionadas para el modelo. Para esto utilicamos la correlación de pearson y el análisis de correlación con regresión lineal de la libreria stats.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. ¿Cuál es tu modelo final y qué nivel de calidad tiene?**\n",
    "\n",
    "El modelo final fue la Red Neuronal Multicapa la cual consta de 5 capas, la primera con 128 neuronas, la segunda con 64 neuronas, la tercera con 32 neuronas, la cuarta con 16 neuronas y la última con una neurona para la clasificación.\n",
    "\n",
    "Las 4 primeras capas tiene función de activación RELU y la ultima sigmoid. Además se utilizó como función de perdida 'binary_crossentropy' y el optimizador adam con 0.0005 de tasa de aprendizaje.\n",
    "\n",
    "El modelo al ser probado con los datos de testeo, obtuvo una calidad de 0.8510 de métrica AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabla de resultados**\n",
    "|Modelos\t|ROC_AUC|\n",
    "|:----------- |:---------:|\n",
    "|Red Neuronal|\t0.851063|\n",
    "|Random_Forest|\t0.842596|\n",
    "|logistic_regression|\t0.842856|\n",
    "|Light_GBM\t|0.830455|\n",
    "|Cat_boost\t|0.849412|\n",
    "|XG_boost\t|0.817874|"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
